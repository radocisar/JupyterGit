{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# NLP Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stockerbot-export.csv contains around 28000 tweets about financial companies and they are labelled with the company the tweet is about.\n",
    "\n",
    "Your task is to create a model which can correctly identify the company the tweet is about.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Open the dataframe\n",
    "\n",
    "Hint: the data may need cleaning, set the error_bad_lines flag to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28264, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 731: expected 8 fields, saw 13\\nSkipping line 2836: expected 8 fields, saw 15\\nSkipping line 3058: expected 8 fields, saw 12\\nSkipping line 3113: expected 8 fields, saw 12\\nSkipping line 3194: expected 8 fields, saw 17\\nSkipping line 3205: expected 8 fields, saw 17\\nSkipping line 3255: expected 8 fields, saw 17\\nSkipping line 3520: expected 8 fields, saw 17\\nSkipping line 4078: expected 8 fields, saw 17\\nSkipping line 4087: expected 8 fields, saw 17\\nSkipping line 4088: expected 8 fields, saw 17\\nSkipping line 4499: expected 8 fields, saw 12\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>symbols</th>\n",
       "      <th>company_names</th>\n",
       "      <th>url</th>\n",
       "      <th>verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1019696670777503700</td>\n",
       "      <td>VIDEO: ‚ÄúI was in my office. I was minding my o...</td>\n",
       "      <td>Wed Jul 18 21:33:26 +0000 2018</td>\n",
       "      <td>GoldmanSachs</td>\n",
       "      <td>GS</td>\n",
       "      <td>The Goldman Sachs</td>\n",
       "      <td>https://twitter.com/i/web/status/1019696670777...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1019709091038548000</td>\n",
       "      <td>The price of lumber $LB_F is down 22% since hi...</td>\n",
       "      <td>Wed Jul 18 22:22:47 +0000 2018</td>\n",
       "      <td>StockTwits</td>\n",
       "      <td>M</td>\n",
       "      <td>Macy's</td>\n",
       "      <td>https://twitter.com/i/web/status/1019709091038...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1019711413798035500</td>\n",
       "      <td>Who says the American Dream is dead? https://t...</td>\n",
       "      <td>Wed Jul 18 22:32:01 +0000 2018</td>\n",
       "      <td>TheStreet</td>\n",
       "      <td>AIG</td>\n",
       "      <td>American</td>\n",
       "      <td>https://buff.ly/2L3kmc4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1019716662587740200</td>\n",
       "      <td>Barry Silbert is extremely optimistic on bitco...</td>\n",
       "      <td>Wed Jul 18 22:52:52 +0000 2018</td>\n",
       "      <td>MarketWatch</td>\n",
       "      <td>BTC</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>https://twitter.com/i/web/status/1019716662587...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1019718460287389700</td>\n",
       "      <td>How satellites avoid attacks and space junk wh...</td>\n",
       "      <td>Wed Jul 18 23:00:01 +0000 2018</td>\n",
       "      <td>Forbes</td>\n",
       "      <td>ORCL</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>http://on.forbes.com/6013DqDDU</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text  \\\n",
       "0  1019696670777503700  VIDEO: ‚ÄúI was in my office. I was minding my o...   \n",
       "1  1019709091038548000  The price of lumber $LB_F is down 22% since hi...   \n",
       "2  1019711413798035500  Who says the American Dream is dead? https://t...   \n",
       "3  1019716662587740200  Barry Silbert is extremely optimistic on bitco...   \n",
       "4  1019718460287389700  How satellites avoid attacks and space junk wh...   \n",
       "\n",
       "                        timestamp        source symbols      company_names  \\\n",
       "0  Wed Jul 18 21:33:26 +0000 2018  GoldmanSachs      GS  The Goldman Sachs   \n",
       "1  Wed Jul 18 22:22:47 +0000 2018    StockTwits       M             Macy's   \n",
       "2  Wed Jul 18 22:32:01 +0000 2018     TheStreet     AIG           American   \n",
       "3  Wed Jul 18 22:52:52 +0000 2018   MarketWatch     BTC            Bitcoin   \n",
       "4  Wed Jul 18 23:00:01 +0000 2018        Forbes    ORCL             Oracle   \n",
       "\n",
       "                                                 url  verified  \n",
       "0  https://twitter.com/i/web/status/1019696670777...      True  \n",
       "1  https://twitter.com/i/web/status/1019709091038...      True  \n",
       "2                            https://buff.ly/2L3kmc4      True  \n",
       "3  https://twitter.com/i/web/status/1019716662587...      True  \n",
       "4                     http://on.forbes.com/6013DqDDU      True  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../assets/data/stockerbot-export.csv\", error_bad_lines=False)\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check the columns of the dataframe\n",
    "\n",
    "Identify the column related to tweets and the one related to the companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'text', 'timestamp', 'source', 'symbols', 'company_names', 'url',\n",
       "       'verified'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Transform the tweets into `computer-friendly` data\n",
    "\n",
    "Think of the 3 steps to clean documents seen in the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VIDEO: ‚ÄúI was in my office. I was minding my own business...‚Äù ‚ÄìDavid Solomon tells $GS interns how he learned he wa‚Ä¶ https://t.co/QClAITywXV'\n",
      " \"The price of lumber $LB_F is down 22% since hitting its YTD highs. The Macy's $M turnaround is still happening.‚Ä¶ https://t.co/XnKsV4De39\"\n",
      " 'Who says the American Dream is dead? https://t.co/CRgx19x7sA' ...\n",
      " \"RT @invest_in_hd: 'Nuff said!  $TEL #telcoin #Telfam #crypto #Blockchain #ethereum #bitcoin $BTC $ETH https://t.co/dkRvaYzgcd\"\n",
      " '„Äê‰ªÆÊÉ≥ÈÄöË≤®„Äë„Éì„ÉÉ„Éà„Ç≥„Ç§„É≥„ÅÆ‰æ°Ê†º‰∏äÊòá„ÄÅÔºòÔºê‰∏áÂÜÜÂè∞ÂõûÂæ©\\u3000Á¥ÑÔºë„Ç´ÊúàÂçä„Å∂„Çä\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000$BTC https://t.co/1OaM6ANOLX https://t.co/Ezd82kCt9L'\n",
      " 'Stellar $XLM price: $0.297852 Binance registration is now OPEN for limited time! üí∏ üí∞  ‚û°Ô∏è‚Ä¶ https://t.co/TteerEnNjo']\n",
      "The Goldman Sachs\n"
     ]
    }
   ],
   "source": [
    "reviews=df[\"text\"].values\n",
    "company_names=df[\"company_names\"]\n",
    "print(reviews)\n",
    "print(company_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stellar',\n",
       " '$xlm',\n",
       " 'price:',\n",
       " '$0.297852',\n",
       " 'binance',\n",
       " 'registration',\n",
       " 'is',\n",
       " 'now',\n",
       " 'open',\n",
       " 'for',\n",
       " 'limited',\n",
       " 'time!',\n",
       " 'üí∏',\n",
       " 'üí∞',\n",
       " '‚û°Ô∏è‚Ä¶',\n",
       " 'https://t.co/tteerennjo']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lowercasing\n",
    "for review in reviews:\n",
    "    words=review.split()\n",
    "\n",
    "words[:10]\n",
    "lower_words = [w.lower() for w in words]\n",
    "lower_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "stopwords = nltk_stopwords.words('english')\n",
    "print(len(stopwords))\n",
    "stopwords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words in the original document 25685\n",
      "number of words in the original document, excluding stopwords 25685\n"
     ]
    }
   ],
   "source": [
    "print(\"number of words in the original document\", len(set(reviews)))\n",
    "useful_words = [word for word in reviews if word not in stopwords]\n",
    "print(\"number of words in the original document, excluding stopwords\", len(set(useful_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['video:', '‚Äúi', 'office.', 'minding', 'business...‚Äù', '‚Äìdavid', 'solomon', 'tells', '$gs', 'interns']\n",
      "['video:', '‚Äúi', 'office.', 'mind', 'business...‚Äù', '‚Äìdavid', 'solomon', 'tell', '$gs', 'intern']\n"
     ]
    }
   ],
   "source": [
    "#stemming\n",
    "stemmed_words = [stemmer.stem(word) for word in useful_words]\n",
    "print(useful_words[:10])\n",
    "print(stemmed_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['video:', '‚Äúi', 'office.', 'minding', 'business...‚Äù', '‚Äìdavid', 'solomon', 'tells', '$gs', 'interns']\n",
      "['video:', '‚Äúi', 'office.', 'mind', 'business...‚Äù', '‚Äìdavid', 'solomon', 'tell', '$gs', 'intern']\n",
      "['video:', '‚Äúi', 'office.', 'mind', 'business...‚Äù', '‚Äìdavid', 'solomon', 'tell', '$gs', 'intern']\n"
     ]
    }
   ],
   "source": [
    "#lemmatisation\n",
    "from nltk import WordNetLemmatizer\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "lemmatised_words = [lem.lemmatize(word, 'v') for word in useful_words]\n",
    "print(useful_words[:10])\n",
    "print(stemmed_words[:10])\n",
    "print(lemmatised_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIDEO: ‚ÄúI was in my office. I was minding my own business...‚Äù ‚ÄìDavid Solomon tells $GS interns how he learned he wa‚Ä¶ https://t.co/QClAITywXV\n",
      "video: ‚Äúi was in my office. i was mind my own business...‚Äù ‚Äìdavid solomon tell $gs intern how he learn he wa‚Ä¶ https://t.co/qclaitywxv\n"
     ]
    }
   ],
   "source": [
    "#apply stemming\n",
    "df[\"text_stemmed\"] = df[\"text\"].apply(lambda x: \" \".join([stemmer.stem(w) for w in x.split()]))\n",
    "print(df[\"text\"].values[0])\n",
    "print(df[\"text_stemmed\"].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: Split the dataset into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Twenty-First Century Fox                  131\n",
       "Alphabet Inc.                             116\n",
       "Discovery                                 102\n",
       "Netflix                                   101\n",
       "Momo Inc.                                 100\n",
       "Eversource Energy                         100\n",
       "The Gap                                   100\n",
       "M&T Bank Corporation                      100\n",
       "Honeywell International Inc.              100\n",
       "Applied Materials                         100\n",
       "Masco Corporation                          99\n",
       "Essex Property Trust                       99\n",
       "Groupon                                    99\n",
       "Mohawk Industries                          99\n",
       "BlackRock                                  97\n",
       "TE Connectivity Ltd.                       97\n",
       "Ingersoll-Rand Plc                         97\n",
       "Hilton Worldwide Holdings Inc.             97\n",
       "United Parcel Service                      97\n",
       "Dominion Energy                            96\n",
       "Nutanix                                    96\n",
       "Discover Financial Services                95\n",
       "Loews Corporation                          95\n",
       "AbbVie Inc.                                95\n",
       "Omisego                                    95\n",
       "McKesson Corporation                       94\n",
       "International Paper Company                94\n",
       "Petr√≠√´_leo Brasileiro S.A. - Petrobras     94\n",
       "The Hershey Company                        94\n",
       "Arconic Inc.                               93\n",
       "                                         ... \n",
       "Baker Hughes                               22\n",
       "Signet Jewelers Limited                    21\n",
       "Acuity Brands                              18\n",
       "Ambev S.A.                                 17\n",
       "H&R Block                                  16\n",
       "Cleveland-Cliffs Inc.                      15\n",
       "Dover Corporation                          14\n",
       "The Interpublic Group of Companies         13\n",
       "CMS Energy Corporation                     12\n",
       "Navient Corporation                        11\n",
       "Total System Services                       8\n",
       "HP                                          2\n",
       "Endo                                        2\n",
       "Harris                                      1\n",
       "Northern                                    1\n",
       "JD                                          1\n",
       "CBS                                         1\n",
       "Time Warner                                 1\n",
       "Twitter                                     1\n",
       "eBay                                        1\n",
       "Facebook*Alphabet*Alphabet                  1\n",
       "The Goldman Sachs                           1\n",
       "MGM Resorts                                 1\n",
       "American                                    1\n",
       " name                                       1\n",
       "Amazon*The Gap                              1\n",
       "Macy's                                      1\n",
       "Alphabet                                    1\n",
       "Oracle                                      1\n",
       "Intel*U.S.                                  1\n",
       "Name: company_names, Length: 461, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[\"text_stemmed\"]\n",
    "y = df[\"company_names\"]\n",
    "\n",
    "# stratify keeps the proportions\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "y.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. The additional step is to transform the tweets into vectors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33453\n",
      "['1858', '185c', '186', '1860s', '187', '1870', '1885', '1895460', '189xwovcqu', '18byjsdc1o']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer(binary=True,\n",
    "                      stop_words='english',\n",
    "                      lowercase=True # default\n",
    "                     )\n",
    "\n",
    "# starting from our 2860 documents we took for training set, we translate them into bag of words, \n",
    "# i.e. dictionaries of word count\n",
    "X_train_text = vec.fit_transform(X_train)\n",
    "X_test_text = vec.transform(X_test)\n",
    "\n",
    "print(len(vec.vocabulary_))\n",
    "# look at some random features\n",
    "print(vec.get_feature_names()[1000:1010])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Use one classification technique to correctly flag the tweets\n",
    "\n",
    "Hint: this is not a binary classification, but a multinomial one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.99629925 -5.80537986 -5.89020343 -5.36862796 -5.55869872 -5.83488845\n",
      " -5.75131165 -5.9508458  -5.60477304 -5.82671837 -5.61977111 -5.70533605\n",
      " -5.88248528 -4.57143688 -5.84891383 -5.80149734 -5.68052632 -5.89436081\n",
      " -5.77734259 -5.51734837 -5.70119809 -5.71883307 -5.94300933 -5.96017828\n",
      " -5.94591003 -6.01934874 -5.43714227 -5.95453348 -5.79116069 -6.01774532\n",
      " -5.82559347 -5.84026459 -5.98784609 -5.74422044 -5.94672844 -5.81575191\n",
      " -5.97584624 -5.96988129 -6.09942248 -5.86019356 -5.58279181 -5.85611472\n",
      " -5.77457873 -5.74983554 -5.91532381 -5.83475538 -5.98596459 -5.62426399\n",
      " -5.85926158 -5.49272488 -5.89653873 -5.95047416 -5.81859521 -5.9161285\n",
      " -5.73662923 -4.9287544  -5.84466931 -5.93652577 -5.78244633 -5.931577\n",
      " -5.89514568 -5.90312102 -5.80298059 -5.99135409 -5.74962481 -5.53887399\n",
      " -5.88291249 -5.76318055 -5.86330825 -5.74142157 -5.90431826 -5.53240882\n",
      " -5.65602158 -5.62347862 -5.70761595 -5.5392319  -5.69055534 -5.79927854\n",
      " -5.86413204 -5.82120266 -6.01075297 -6.02775521 -5.72007048 -5.8818226\n",
      " -5.90000498 -6.01497824 -5.80251519 -5.80682329 -5.81079142 -5.9949037\n",
      " -5.89535758 -5.86694529 -5.82044889 -5.9299472  -5.63624586 -5.9147999\n",
      " -5.86863873 -5.72031801 -5.5211622  -5.68245948 -5.79349384 -5.93442607\n",
      " -5.89481043 -5.99652734 -5.63046468 -5.1995385  -5.85494367 -5.6360985\n",
      " -5.82614585 -5.93743139 -5.92187674 -5.93693278 -5.92062719 -5.85321981\n",
      " -5.84798603 -5.8677693  -5.8028823  -5.8557606  -5.74917282 -5.9103777\n",
      " -5.75510757 -5.79848274 -5.89680852 -5.87696076 -5.94749149 -5.89471439\n",
      " -5.78024658 -5.92851943 -5.35693259 -5.70539847 -5.70379081 -6.17826142\n",
      " -5.64587769 -5.86668233 -5.83728097 -6.0452428  -5.8909815  -5.7936685\n",
      " -5.86396177 -5.44930126 -5.92464974 -5.92372401 -5.87529522 -5.84682419\n",
      " -5.81511877 -5.8360094  -5.43036616 -5.88123978 -5.84823428 -5.79128787\n",
      " -5.65136587 -5.80839626 -5.87094421 -5.96825745 -5.67582597 -5.77020889\n",
      " -5.86365102 -5.95834365 -5.62892787 -5.5217653  -5.73104725 -5.94773701\n",
      " -5.75043425 -5.73024447 -5.62853731 -5.8592742  -5.86386335 -5.9481057\n",
      " -5.98700924 -5.74866608 -5.10757774 -6.02580886 -5.89936214 -5.66520393\n",
      " -5.91987153 -5.84785481 -5.96057248 -5.80607311 -5.66342897 -5.90556071\n",
      " -5.94998637 -5.81230884 -5.85878027 -5.58380063 -5.8707652  -5.9337202\n",
      " -5.99519701 -5.53525284 -5.74619284 -5.68988118 -5.83893624 -5.83946948\n",
      " -5.75073326 -5.82754726 -5.86320302 -5.808913   -6.02384354 -5.84113166\n",
      " -5.87778399 -6.00386135 -5.96818818 -5.87731699 -5.81118274 -5.65424683\n",
      " -5.99474805 -5.74019025 -5.52562947 -5.76779186 -5.86700963 -5.90531811\n",
      " -5.85852967 -5.52303826 -5.84097344 -5.7482223  -5.85622176 -5.7528014\n",
      " -5.82659307 -5.88484066 -5.90712428 -5.90176131 -5.93546393 -5.59375411\n",
      " -5.73329187 -5.73428153 -5.73467923 -5.80557753 -5.65286699 -5.83539505\n",
      " -5.92620232 -5.84252379 -5.81902315 -5.71521035 -5.66119027 -5.81188197\n",
      " -6.0095084  -5.53270475 -5.77723039 -5.73432504 -5.94018809 -5.91552371\n",
      " -5.85352462 -5.86049184 -5.2014935  -5.726587   -5.67101998 -5.77239007\n",
      " -5.83141481 -5.82417603 -5.87010955 -5.91246061 -5.5223567  -5.10492006\n",
      " -5.96920036 -5.7428237  -5.86318893 -5.7694761  -6.00979142 -5.63546607\n",
      " -6.04715701 -5.83410487 -5.87813045 -5.91365554 -5.79093193 -5.61336546\n",
      " -5.86045136 -5.79527473 -5.95301629 -5.91376644 -5.73496014 -5.67143805\n",
      " -5.76075236 -5.69048811 -5.81936786 -5.94960444 -5.80183831 -5.94017372\n",
      " -5.9440547  -5.79494742 -5.61570551 -5.53068756 -6.02152657 -5.567841\n",
      " -6.18098275 -5.78392712 -5.90092907 -5.60988665 -5.64588056 -5.88037395\n",
      " -5.81100502 -6.01871368 -5.90877248 -5.8655376  -5.74504767 -5.58992024\n",
      " -5.85678527 -5.90636582 -5.85551858 -5.67743704 -5.84311654 -5.78492927\n",
      " -5.97226225 -5.80995239 -6.00640758 -5.8647068  -5.75131345 -5.82648643\n",
      " -5.62370726 -5.70151076 -5.53073975 -4.98507802 -5.85436647 -5.76757599\n",
      " -5.97486387 -5.79962422 -5.79221282 -5.83431313 -6.00210406 -5.81359344\n",
      " -5.8901207  -5.88922168 -5.95297601 -5.8177706  -5.92314705 -6.05459527\n",
      " -5.35473367 -5.80527266 -5.76554473 -5.86168567 -5.73374735 -5.73849727\n",
      " -5.76454573 -5.73195687 -5.84330219 -5.90941106 -5.72513548 -5.77445604\n",
      " -5.88453083 -5.76434814 -6.00350043 -5.82920455 -5.92511226 -5.67686121\n",
      " -5.64736703 -5.77828637 -5.61228292 -5.92011099 -5.8001601  -5.83795636\n",
      " -5.89127035 -5.60643032 -5.9512562  -5.83489268 -5.52952806 -5.66690959\n",
      " -5.81508544 -5.84199344 -5.86405168 -5.60084567 -5.49094576 -5.8991143\n",
      " -5.83831739 -4.8876626  -5.97065653 -5.84395831 -5.80454633 -5.7292127\n",
      " -5.98574343 -5.90897467 -5.766137   -5.85873708 -5.86920385 -5.7967615\n",
      " -5.84245017 -5.95777234 -5.69247414 -5.34076184 -5.86817701 -5.84412506\n",
      " -5.899199   -5.98339138 -5.7899868  -5.88560334 -5.67617808 -6.22546436\n",
      " -5.72032718 -5.88796136 -6.00236836 -5.84915836 -6.01286093 -5.77814736\n",
      " -5.82926185 -5.89431217 -6.01929614 -5.93232918 -5.80004509 -5.795882\n",
      " -5.98388066 -5.66900571 -5.76836084 -5.87549829 -5.85711269 -5.75859019\n",
      " -6.02256185 -5.90479734 -5.89367888 -6.00037026 -5.94570014 -5.88112485\n",
      " -5.77423661 -5.7265742  -5.56897323 -6.00612554 -5.81066431 -5.83465104\n",
      " -5.87488281 -5.59132433 -5.58314175 -5.75069836 -5.84291289 -5.94611485\n",
      " -5.70812624 -5.65875674 -5.80768138 -5.58382972 -5.59637677 -5.8501707\n",
      " -5.67716699 -5.80050184 -5.43611587 -5.32037367 -6.04547622 -5.99410157\n",
      " -5.73447959 -5.80047591 -5.89491908 -6.01047417 -5.64752587 -5.9045779\n",
      " -5.68650254 -5.86370414 -5.79616542 -5.82335062 -5.93536044 -5.93669566\n",
      " -5.72730745 -5.89002798 -5.95414656 -5.66433602 -5.79630407 -5.82993865\n",
      " -5.65333567 -5.93649997 -5.73394114 -5.93031237 -5.77914364 -5.77993554\n",
      " -5.48815171 -5.86390927] [[-1.46502319e-01 -2.20900977e-03 -2.43198144e-06 ... -1.72319391e-03\n",
      "  -1.72319391e-03 -7.59026422e-03]\n",
      " [-9.65938505e-02 -2.51071096e-03 -3.92578502e-06 ... -2.22925362e-03\n",
      "  -2.22925362e-03 -9.88905033e-03]\n",
      " [ 4.51419532e-03 -2.38318748e-03 -2.26985678e-05 ... -1.64900965e-03\n",
      "  -1.64900965e-03 -7.60863899e-03]\n",
      " ...\n",
      " [-2.69293567e-01 -2.56889122e-03 -4.68582097e-06 ... -2.11307537e-03\n",
      "  -2.11307537e-03 -1.28774090e-02]\n",
      " [-1.05729854e-01 -2.76561821e-03 -4.58450967e-06 ... -2.66932520e-03\n",
      "  -2.66932520e-03 -1.09179924e-02]\n",
      " [-1.99820404e-01 -2.74949563e-03 -2.57868198e-06 ... -2.14934564e-03\n",
      "  -2.14934564e-03 -1.30096147e-02]]\n"
     ]
    }
   ],
   "source": [
    "# in order to use LogisticRegression we must have numerical values as X_train\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_text, y_train)\n",
    "#print(lr.intercept_, lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Measure the accuracy of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRA: why is the accuracy so low? What can you do to improve it?\n",
    "\n",
    "Hint: try to segment your dataset into groups and apply different models to different groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
